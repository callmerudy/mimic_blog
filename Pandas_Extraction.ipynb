{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "html {\n",
       "  font-size: 62.5% !important; }\n",
       "body {\n",
       "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
       "  line-height: 1.6 !important;\n",
       "  font-weight: 400 !important;\n",
       "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "  color: #222 !important; }\n",
       "\n",
       "div{ border-radius: 0px !important;  }\n",
       "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  color: #333 !important;\n",
       "  margin-top: 0 !important;\n",
       "  margin-bottom: 2rem !important;\n",
       "  font-weight: 300 !important; }\n",
       "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
       "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
       "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
       "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
       "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
       "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
       "\n",
       "p {\n",
       "  margin-top: 0 !important; }\n",
       "  \n",
       "a {\n",
       "  color: #1EAEDB !important; }\n",
       "a:hover {\n",
       "  color: #0FA0CE !important; }\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import urllib2\n",
    "HTML(urllib2.urlopen('https://gist.githubusercontent.com/mattlewissf/83989910849fdb4a04a72d431e84053f/raw/cefa015a9065665faccd0219774c7087be7d21a8/skeleton.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIMIC Deep Dive - Extracting Features into a Pandas Dataframe\n",
    "**[Intro](#intro)**   \n",
    "**[30 Day Readmission](#30_day_readmission)**  \n",
    "**[The MIMIC Dataset](#mimic_dataset)**  \n",
    "**[Setting up the database](#setting_up_db)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We've set up functions to determine and extract individual features; now we need to set up a way to run all of them on a given patient record. We've set up a single function, apply_extractors(), that takes a person record and returns a list of feature variables:\n",
    "\n",
    "\n",
    "It's almost time to run our extraction and move toward actually fitting our model and seeing how well our predcitive ability is. Here's a quick look back at what we've done to get to this point: \n",
    "\n",
    "- Downloaded the data \n",
    "- Prepped the data\n",
    "- Found that that SQLAlchemy is really slow and moved to another ORM \n",
    "- Started writing extractors for basic features\n",
    "- Thought more about what features we'd like to see \n",
    "- Built a way to apply Charlson codes to our admission records \n",
    "- Categorized dx codes into CCS categories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas'></a>\n",
    "#### Extracting features\n",
    "\n",
    "We've set up functions to determine and extract individual features; now we need to set up a way to run all of them on a given patient record. We've set up a single function, apply_extractors(), that takes a person record and returns a list of feature variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_extractors(person, codeset):\n",
    "        assign_index_record(person)\n",
    "        if person.index_admission == None:\n",
    "            return None\n",
    "        if person.index_admission.admission_type == 'NEWBORN':\n",
    "            return None\n",
    "        person_index_age = get_person_index_age(person)\n",
    "        if person_index_age > 120: \n",
    "            return None\n",
    "        person_id = person.person_id\n",
    "        index_admission_length = get_index_admission_length(person)\n",
    "        index_admission_type_features = get_index_admission_type(person)\n",
    "        person_gender = get_person_gender(person)\n",
    "        ethnicity_features = get_person_ethnicity(person)\n",
    "        marital_features = get_person_marital(person)\n",
    "        admission_rate = get_admission_rate(person)\n",
    "        codes = get_person_icd_codes(person)\n",
    "        # ETC.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up a dataframe\n",
    "\n",
    "Now that we've got a way of getting our features, the next step is to set up a Pandas dataframe to hold all of it.  [Pandas](http://pandas.pydata.org/pandas-docs/stable/) is \"a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive.\" In short, Pandas sets up a tabular data scheme, a 'dataframe', and allows for easy (and powerful) data manipulation. Super awesome. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "We're going to want to set up a dataframe and then start extracting features directly into it. Fist, we'll want to set up a blank dataframe by creating columns that match our features and assigning those to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_columns = [\"person_id\", \"person_index_age\",\"index_admission_length\",\"person_gender\", \"admission_rate\"]\n",
    "[df_columns.append(feature) for feature in index_admission_types.keys()]\n",
    "[df_columns.append(feature) for feature in ethnicity_values.keys()]\n",
    "[df_columns.append(feature) for feature in marital_values.keys()]\n",
    "[df_columns.append(feature) for feature in charleston_values.keys()]\n",
    "[df_columns.append(feature) for feature in sorted(codeset.dx_single_level_codes.keys())]\n",
    "df_columns.append(\"readmit_30\") \n",
    "empty_col = [0 for x in df_columns]\n",
    "np_data = np.array(empty_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a dataframe with the appropriate setup, we can start iterating through patient records and assigning features to differnet columns in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# within the extract_to_dataframe() function... \n",
    "\n",
    "empty_col = [0 for x in df_columns]\n",
    "    np_data = np.array(empty_col)\n",
    "\n",
    "    for person in persons: \n",
    "        features = apply_extractors(person, codeset) \n",
    "        if features: \n",
    "            np_data = np.vstack((np_data, features))\n",
    "        \n",
    "    df = pd.DataFrame(data=np_data[1:,:], columns=df_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in short, we're going through the entire process here to extract features. For each patient record we are iterating through (and for the whole set it is > 40k): \n",
    "- Create a OMOP Person object and associated records (ICD codes, etc)\n",
    "- Calculate an index admission, and assign that to the Person itself \n",
    "- Extract and calculate features based off of records with their index admission as anchor\n",
    "- Determine whether they represented a readmit within 30 days of their index admission discharge\n",
    "- Assign these features to the dataframe as binary or continuous values\n",
    "\n",
    "<br></br>\n",
    "\n",
    "For all of the records in MIMIC, this can take a while.. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<img src='https://media.giphy.com/media/LQoYS7mhDQkRG/giphy.gif' width=\"400\" height=\"400\" align='float' margin-right=50px />\n",
    "<br></br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "And...  Almost...\n",
    "\n",
    "<br></br>\n",
    "\n",
    "Done! After doing our data munging and preprocessing, we're finally at the stage where all of our data is ready and sitting in a pandas dataframe:\n",
    "\n",
    "```\n",
    "35446 entries, 0 to 35445\n",
    "memory usage: 15.7 MB\n",
    "58 features\n",
    "```\n",
    "\n",
    "We can used df.head() to check out the first few lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Next  |   [Thinking about Classification]()**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
