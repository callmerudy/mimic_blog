{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "html {\n",
       "  font-size: 62.5% !important; }\n",
       "body {\n",
       "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
       "  line-height: 1.6 !important;\n",
       "  font-weight: 400 !important;\n",
       "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "  color: #222 !important; }\n",
       "\n",
       "div{ border-radius: 0px !important;  }\n",
       "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  color: #333 !important;\n",
       "  margin-top: 0 !important;\n",
       "  margin-bottom: 2rem !important;\n",
       "  font-weight: 300 !important; }\n",
       "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
       "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
       "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
       "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
       "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
       "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
       "\n",
       "p {\n",
       "  margin-top: 0 !important; }\n",
       "  \n",
       "a {\n",
       "  color: #1EAEDB !important; }\n",
       "a:hover {\n",
       "  color: #0FA0CE !important; }\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import urllib2\n",
    "HTML(urllib2.urlopen('https://gist.githubusercontent.com/mattlewissf/83989910849fdb4a04a72d431e84053f/raw/cefa015a9065665faccd0219774c7087be7d21a8/skeleton.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIMIC Deep Dive - Fitting the Model and Plotting the ROC Curve\n",
    "**[Intro](#intro)**   \n",
    "**[30 Day Readmission](#30_day_readmission)**  \n",
    "**[The MIMIC Dataset](#mimic_dataset)**  \n",
    "**[Setting up the database](#setting_up_db)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cross-validation set up, it is time for us to start actually fitting different classifiers to our data. But before we do that: what do we mean by 'fitting' a model? \n",
    "\n",
    "In terms of what we are doing code wise: not much. Here's an example of us fitting a classifier to our data, again using our k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " for train, test in kf.split(X):\n",
    "        clf.fit(X.loc[train], y.loc[train])\n",
    "        prob = clf.predict_proba(X.loc[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, we're applying a given alogrithm to our data, and getting back a representation of the relationship between our features (or predictors) and outcomes so that we can most accurately predict future outcomes. In our case, these alogrithms are different implementations of classifiers that we're importing from sk-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using the k-fold technique, we're actually re-fitting the model to new data each time we iterate through the differently slices of our larger data set, and we're likely to get a different 'fit' each time that we do so. Since what we want to be able to measure at this point is the AUC of a given classifier for our data, we'll want to take the mean AUC of our data. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "Here's some code that calculates the mean AUC for a given classifier and dataset, leaning heaviliy on sk-learn methods like roc_curve(), clf.predict_proba, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_auc(df, clf):\n",
    "    kf = KFold(n_splits = 10) \n",
    "    kf.get_n_splits(X)\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    for train, test in kf.split(X):\n",
    "        clf.fit(X.loc[train], y.loc[train])\n",
    "        prob = clf.predict_proba(X.loc[test])\n",
    "        fpr, tpr = roc_curve(y[test], prob[:,1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plots.append([fpr, tpr]) # for plotting\n",
    "\n",
    "    mean_tpr /= kf.get_n_splits(X,y)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    #... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to want to be able to plot ROC curves for each k-fold. We'll be using [matplotib.pyplot](https://matplotlib.org/api/pyplot_summary.html) for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for plot in plots: \n",
    "    plt.plot(plot[0], plot[1], color='b')\n",
    "    plt.plot(mean_fpr, mean_tpr, color ='r')\n",
    "    plt.xlabel('{0}  -- mean auc = {1}'.format(clf, mean_auc))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that - we're in a position to actually determine what our ROC curves look like for different classifiers, and we can start to determine what classifier gives us the best predicitvie ability for our data. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "Without further ado, let's take a look at the calcualted AUC for all of our classifiers, based on the maximum number of features that we've extracted: \n",
    "\n",
    "- RandomForestClassifier -  0.6706\n",
    "- AdaBoostClassifier - 0.8037\n",
    "- **GradientBoostingClassifier - 0.8127**\n",
    "- DecisionTreeClassifier - 0.7452\n",
    "- LogisticRegression -  0.7769\n",
    "- LogisticRegressionCV - 0.7718\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're seeing what looks like a clear winner here with our GBC classifer. Next, we'll look into hyperparameter tuning, and do some analysis of our results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Next  |   [Results and Analysis]()**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
